{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 Machine Learning Basics\n",
    "\n",
    "## 5.1 Learning Algorithms\n",
    "\n",
    "## 5.4 Estimators, Bias and Variance\n",
    "\n",
    "### 5.4.1 Point Estimation\n",
    "\n",
    "- A **point estimator** or **statistic** is any function of data:\n",
    "\n",
    "$$ \\hat{\\theta}_m = g(x^{(1)},\\dots,x^{(m)} $$\n",
    "\n",
    "- **frequentist perspective on statistics**: assume the parameter value $\\theta$ is fixed but unknown, while the point estimate $\\hat{\\theta}$ is a function of the data. Since the data is drawn from a random process, any function of the data is random. Therefore $\\hat{\\theta}$ is a random variable.\n",
    "\n",
    "### 5.4.2 Bias\n",
    "\n",
    "- The bias of an estimator is defined as:\n",
    "\n",
    "$$ bias(\\hat{\\theta}_m) = \\mathbb{E}(\\hat{\\theta}_m) - \\theta$$\n",
    "\n",
    "- An estimator $\\hat{\\theta}_m$ is said to be **unbiased** if $bias(\\hat{\\theta}_m) = 0$, which implies that $\\mathbb{E}(\\hat{\\theta}_m) = \\theta$. **asymptotically unbiased** if $\\lim_{m \\to \\infty}bias(\\hat{\\theta}_m) = 0$\n",
    "\n",
    "### 5.4.3 Variance and Standard Error(标准误差)\n",
    "\n",
    "- Standard Error是样本统计量的Standard Deviation, 而不是样本的Standard Deviation. 描述对应样本统计量抽样分布的离散程度及衡量对应样本统计量误差大小的尺度\n",
    "\n",
    "- The **variance** of an estimator is simply:\n",
    "\n",
    "$$Var(\\hat{\\theta})$$\n",
    "\n",
    "- standard error of the mean is given by\n",
    "\n",
    "$$SE(\\hat{\\mu}_m) = \\sqrt{Var \\bigg[\\frac{1}{m}\\sum_{i=1}^m x^{(i)} \\bigg]} = \\frac {\\sigma} {\\sqrt{m}}$$\n",
    "\n",
    "- difference between **estimation variance** and **sample variance**:\n",
    "  - Starting with an estimator like the sample mean or sample variance, we could in principle write down all the possible values it could take, for every possible sample of size n from a given population. The estimation variance is the variance of that large set of values. It measures how much, well, variance there is in an estimator from sample to sample. For an estimator like the sample mean which is correct on average (unbiased), the estimation variance measures how accurate it is. Estimation variance is not a term often used: more common is its square root, which is usually called the standard error.\n",
    "  - https://www.quora.com/Is-there-a-difference-between-estimation-variance-and-sample-variance\n",
    "\n",
    "\n",
    "### 5.4.4 Trading off Bias and Variance to Minimize Mean Squared Error\n",
    "\n",
    "- In the case of where generalization error is measured by the MSE(where bias and variance are meaningfull components of generalization error), increasing capacity tends to increase variance and decrease bias.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "MSE = & \\mathbb{E}[(\\hat{\\theta}_m - \\theta)^2] \\\\\n",
    "      & Bias(\\hat{\\theta}_m)^2 + Var(\\hat{\\theta}_m)\n",
    "\\end{align}\n",
    "$$\n",
    "### 5.4.5 Consistency\n",
    "\n",
    "## 5.5 Maximum Likelihood Estimation\n",
    "\n",
    "- MLE can be viewed as minimizing the KL divergence, minimizing KL divergence corresponds exactly to minimizing the cross-entropy between the distributions.\n",
    "\n",
    "- MSE is the cross-entropy between the empirical distribution and a Gaussian model.\n",
    "\n",
    "### 5.5.1 Conditional Log-Likelihood and Mean Squared Error\n",
    "\n",
    "- The two criteria have different values but the same location of the optimum.\n",
    "\n",
    "### 5.5.2 Properties of Maximum Likelihood\n",
    "\n",
    "- consistency\n",
    "- efficiency\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
